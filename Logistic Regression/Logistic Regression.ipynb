{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,weight,bias,lr):\n",
    "        self.weight=weight\n",
    "        self.bias=bias\n",
    "        self.lr=lr\n",
    "        \n",
    "    def sigmoid(self,y):\n",
    "        return np.e**y/(1+np.e**y)\n",
    "    \n",
    "    def grad(self,y,y_pred):\n",
    "        loss_grad = -(y/y_pred-(1-y)/(1-y_pred))\n",
    "        activation_grad = y_pred*(1-y_pred)\n",
    "        return loss_grad*activation_grad\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_real = self.weight @ x + self.bias\n",
    "        y_predict = self.sigmoid(y_real)\n",
    "        return y_predict\n",
    "    \n",
    "    def loss(self,y,y_pred):\n",
    "        return -sum(y*np.log(y_pred)+(1.0-y)*np.log(1.0-y_pred))\n",
    "    \n",
    "    def backward(self,x,y):\n",
    "        y_pred = self.forward(x)\n",
    "        self.weight = self.weight - self.lr*(self.grad(y,y_pred).T*x[:,None]).T\n",
    "        self.bias = self.bias - self.lr*self.grad(y,y_pred)\n",
    "        return self.weight,self.bias\n",
    "    \n",
    "    def fit(self,X,Y,epochs):\n",
    "        for epoch in tqdm.tqdm(range(epochs)):\n",
    "            Loss = 0\n",
    "            accuracy = 0\n",
    "            for x,y in zip(X,Y):\n",
    "                self.weight,self.b = self.backward(x,y)\n",
    "                y_pred = self.forward(x)\n",
    "                if np.argmax(y_pred)==np.argmax(y):\n",
    "                    accuracy+=1.0\n",
    "                Loss+=self.loss(y,y_pred)\n",
    "            if (epoch+1)%10:\n",
    "                print(\"{*\"+str(epoch+1)+\"-epoch} Loss: \"+str(Loss)+\" accuracy: \"+str(accuracy/len(X)))\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        return self.weight,self.bias\n",
    "    \n",
    "    def evaluate(self,X_test,Y_test):\n",
    "        accuracy = 0\n",
    "        for i in range(len(X_test)):\n",
    "            Y_test_pred = self.forward(X_test[i])\n",
    "            if np.argmax(Y_test_pred)==np.argmax(Y_test[i]):\n",
    "                accuracy+=1\n",
    "        print(\"accuracy: \"+str(accuracy/len(X_test)))\n",
    "        \n",
    "    def test(self,X_for_test):\n",
    "        Y_for_test = self.forward(X_for_test)\n",
    "        return np.argmax(Y_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "\n",
    "def one_hot_encoding(index,length_label):\n",
    "    label = np.zeros(length_label)\n",
    "    label[int(index)] = 1\n",
    "    return label\n",
    "\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "classes = list(data.klass.unique())\n",
    "dict_class=[]\n",
    "for i in range(len(classes)):\n",
    "    dict_class.append([classes[i],i])\n",
    "dict_class = dict(dict_class)\n",
    "data = data.replace(dict_class)\n",
    "\n",
    "X = np.array(data.drop('klass',axis=1))\n",
    "y = np.array(data['klass']).astype(float)\n",
    "Y = np.array([one_hot_encoding(i,3) for i in y])\n",
    "\n",
    "X_train = np.concatenate([X[:30],X[50:80],X[100:130]])\n",
    "Y_train = np.concatenate([Y[:30],Y[50:80],Y[100:130]])\n",
    "\n",
    "X_test = np.concatenate([X[30:50],X[80:100],X[130:]])\n",
    "Y_test = np.concatenate([Y[30:50],Y[80:100],Y[130:]])\n",
    "\"\"\"\n",
    "data = pd.read_csv(\"Dataset.csv\")\n",
    "\n",
    "X = np.array(data.drop('klass',axis=1))\n",
    "y = np.array(data['klass']).astype(float)\n",
    "Y = np.array([one_hot_encoding(i,3) for i in y])\n",
    "\n",
    "X_train = np.concatenate([X[:30],X[50:80],X[100:130]])\n",
    "Y_train = np.concatenate([Y[:30],Y[50:80],Y[100:130]])\n",
    "\n",
    "X_test = np.concatenate([X[30:50],X[80:100],X[130:]])\n",
    "Y_test = np.concatenate([Y[30:50],Y[80:100],Y[130:]])\n",
    "\"\"\"\n",
    "w = np.random.rand(Y.shape[-1],X.shape[-1])\n",
    "b = np.random.rand(Y.shape[-1],)\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c226ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "LR = LogisticRegression(w,b,lr)\n",
    "LR.fit(X,Y,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f037282",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262675df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_for_test = np.array([8,3.8,6.4,2])\n",
    "class_test = LR.test(Y_for_test)\n",
    "print(classes[class_test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
